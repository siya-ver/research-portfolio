<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Siya Verma | Research Portfolio</title>
  <link rel="stylesheet" href="assets/css/style.css" />
</head>
<body>
  <header class="topbar">
    <div class="topbar-inner">
      <a class="brand" href="index.html">Siya Verma</a>
      <nav class="nav">
        <a class="nav-link active" href="index.html">About</a>
        <a class="nav-link" href="pages/publications.html">Publications</a>
        <a class="nav-link" href="pages/talks.html">Talks</a>
        <a class="nav-link" href="pages/initiatives.html">Initiatives</a>
        <a class="nav-link" href="pages/web-presence.html">Web presence</a>
      </nav>
    </div>
  </header>

  <main class="layout">
    <aside class="sidebar">
      <img class="avatar" src="assets/img/headshot.jpg" alt="Headshot" />
      <h1 class="name">Siya Verma</h1>
      <p class="subtitle">
        Research portfolio in AI policy, HCI, and public opinion.<br />
        Work presented at APSA, Stanford, Yale, US Congress, and more.
      </p>

      <div class="links">
        <a class="iconlink" href="mailto:siyaver@sas.upenn.edu">Email</a>
        <a class="iconlink" href="https://linkedin.com/in/siyaverma">LinkedIn</a>
        <a class="iconlink" href="https://github.com/siya-ver">GitHub</a>
        <a class="iconlink" href="https://theweeklythesis.substack.com/">Substack</a>
      </div>

      <div class="mini">
        <h3>Focus Areas</h3>
        <ul>
          <li>AI governance and trust</li>
          <li>Human–AI interaction</li>
          <li>Public opinion and deliberation</li>
          <li>Product-facing AI reliability</li>
        </ul>
      </div>
    </aside>

    <section class="content">
      <h2>About</h2>
      <p class="lead">
        This portfolio showcases selected research in AI governance, human–AI interaction,
        education policy, and alignment. My work spans Stanford University’s Deliberative
        Democracy Lab, Wharton’s Human-AI Lab, and startup research at Ezio focused on LLM
        reliability and hallucination detection.
      </p>

      <p>
        My contributions sit at the intersection of research, policy, and product insight.
        I specialize in translating complex qualitative and quantitative findings into
        actionable strategies for product teams, policymakers, and academic audiences.
      </p>

      <h3>Research Projects</h3>

      <div class="list">
        <div class="item">
          <div class="item-title">AI–Human Interaction Dynamics</div>
          <div class="item-meta">
            Lead Author · APSA 2025, Stanford AI Industry Symposium · Forthcoming book chapter (2026)
          </div>
          <p class="item-desc">
            Led qualitative coding of 4,000+ AI community forum transcript lines to analyze
            public opinion on AI–human interaction. Co-authored with researchers from
            Princeton, Yale, and Harvard. Findings are being translated into internal
            insights for a global AI firm.
          </p>
        </div>

        <div class="item">
          <div class="item-title">AI in Education – Global Deliberative Polling</div>
          <div class="item-meta">
            Project and Research Lead · Yale AI Governance Conference · iCivics · US Congress
          </div>
          <p class="item-desc">
            Designed and launched three national deliberative polling events engaging
            students, teachers, and school boards. Results informed education policy
            discussions in Albania and Greece and were presented in briefings to
            45+ members of Congress.
          </p>
          <div class="item-links">
            <a href="#">Student Perspectives Fact Sheet (CSBA)</a>
            <a href="#">Educator Perspectives Fact Sheet (CSBA)</a>
            <a href="#">All Reports</a>
          </div>
        </div>

        <div class="item">
          <div class="item-title">Youth Perspectives on AI and Social Media</div>
          <div class="item-meta">
            Lead Author · APSA 2025 · Under Review
          </div>
          <p class="item-desc">
            Analyzed 400+ responses from first-time voters in “America in One Room: Youth Vote”
            using Excel-based thematic analysis. Focused on youth sentiment around AI,
            privacy, and platform governance.
          </p>
        </div>

        <div class="item">
          <div class="item-title">
            Mental Models of AI Agents: Cross-Cultural Perceptions in the US and India
          </div>
          <div class="item-meta">
            Lead Author · To be presented at AAPOR 2026 · Ongoing
          </div>
          <p class="item-desc">
            Comparative qualitative study of public mental models of AI among U.S. and Indian
            participants in the Frontier AI Industry Forum, organized by Stanford University
            and companies including Meta, DoorDash, and Cohere. Examines implications for
            trust, alignment, and safety communication.
          </p>
        </div>

        <div class="item">
          <div class="item-title">
            Designing Consumer-Facing AI Agents Users Want to Use
          </div>
          <div class="item-meta">
            Research Assistant, Co-Author · Wharton Human-AI Lab · Ongoing
          </div>
          <p class="item-desc">
            Identifying key design patterns across 50+ consumer-facing AI agent applications.
            Work aims to prototype and test an agent with a randomized group of 100 users,
            informing practitioners designing trustworthy AI systems.
          </p>
        </div>
      </div>

      <h3>Hackathons and Applied Work</h3>

      <div class="list">
        <div class="item">
          <div class="item-title">Ezio: LLM Hallucination Detection and Trust Scoring</div>
          <div class="item-meta">
            Co-Founder · Top 10 Finalist, AI Hackathon
          </div>
          <p class="item-desc">
            Designed a research-informed trust scoring framework for LLM outputs using Exa
            and Perplexity APIs. Developed novel weighting across accuracy, sycophancy, and
            reliability grounded in AI and HCI literature.
          </p>
          <div class="item-links">
            <a href="#">Product Overview (Launching January 2026)</a>
          </div>
        </div>

        <div class="item">
          <div class="item-title">Penn AI for Social Good Hackathon Winner (2025)</div>
          <div class="item-meta">
            Best Overall Product · 100+ Teams
          </div>
          <p class="item-desc">
            Built an MVP LLM-based tax assistant for international students and gig workers.
            Selected as Best Overall Product among more than 100 hackathon entries.
          </p>
          <div class="item-links">
            <a href="#">Pitch Deck</a>
          </div>
        </div>

        <div class="item">
          <div class="item-title">The Weekly Thesis</div>
          <div class="item-meta">
            Author · Substack Newsletter
          </div>
          <p class="item-desc">
            Weekly synthesis of technical AI research papers alongside current headlines
            related to AI policy, governance, and safety.
          </p>
          <div class="item-links">
            <a href="https://theweeklythesis.substack.com/">Read on Substack</a>
          </div>
        </div>
      </div>
    </section>
  </main>

  <footer class="footer">
    <div class="footer-inner">
      © <span id="y"></span> Siya Verma
    </div>
  </footer>

  <script>
    document.getElementById("y").textContent = new Date().getFullYear();
  </script>
</body>
</html>
